\section{引言}

%\vspace{10cm}在垂直方向上，两行之间的距离
%随着深度学习等人工智能技术的蓬勃发展，人类在图像识别、语音识别、围棋等领域已经接近人类甚至超越
%人类水平。自然语言处理是实现智能、人机交互的重要基石，

自然语言处理是人工智能的重要分支，是实现人工智能的核心技术，主要研究如何处理、分析以及应用自然语言。教会机器阅读文本并且理解人类语言是自然语言处理领域的重要任务，
机器阅读理解（Machine Reading Comprehension，MRC）的目标就是利用自然语言处理技术使得计算机能够像人一样阅读并且理解文章，
%目的是让机器在接受自然语言输入后给予正确的反馈，
它有着很多应用场景，如搜索引擎中的智能问答，电商领域的智能客服以及对话系统等。

%机器阅读理解是认知智能领域一个具有挑战性的任务，
早在20世纪70年代，学者们就已经意识到机器阅读技术是测试计算机理解人类语言的关键方法，如Lehnert\upcite{Lehnert}构建的QUALM系统。但是系统非常小并且局限于手工编码，很难推广到更大的领域。
%Lehnert\upcite{Lehnert}首先提出
1999年出现首个自动阅读理解测试系统Deep Read,该系统以故事为基础衡量阅读理解任务，利用词袋模型和人工编写规则进行模式匹配，准确率可以达到40\%左右，但是由于依靠手工规则，模型泛化能力很差。
%MCTest数据集于2013年发布，规模很小。
总之由于没有合适的文本表示方法，数据集的规模又比较小，而且
传统方法更多的是在句子级别粒度上回答问题，核心是特征提取，包括的特征主要有依存句法、词频共现和语篇关系等。但是由于特征需要人工制定，鲁棒性差。而且只能从文本中提取浅层特征不能对文本推理，因此达不到真正的阅读理解，
因此早期的MRC系统难以获得期望的性能也不能实际的应用。

随着深度学习的兴起以及NLP领域技术的发展，
%如Word2Vec\upcite{word2vec}、GloVe\upcite{GloVe}等预训练词向量的出现，seq2seq结构的提出，注意力（Attention）机制在NLP领域的应用\upcite{Bahdanau}等。
为了弥补传统MRC技术的缺陷，2015年DeepMind研究员Hermann等人\upcite{Hermann}提出使用神经网络模型解决MRC任务。他们提出一种新颖且代价小的解决方案用来构建MRC领域大规模的监督训练数据，基于此方案他们构建了规模比以往数据集都要大的阅读理解数据集CNN\&Daily Mail，并且提出两个基于神经网络和注意力机制构建的模型（Attentive Reader，Impatient Reader），模型在CNN\&Daily数据集上效果远超过传统方法的效果。
这项工作可以视为机器阅读理解领域的奠基性工作。此后越来越多的学者在这两个模型的基础上构建效果更好的基于神经网络的机器阅读理解模型，也简称为神经机器阅读理解模型。
%，如Chen等人\upcite{AR}使用双线性函数简化Attentive Reader的加法形式，Kadlec等人\upcite{ASR}基于指针网络\cite{Ptr}的思想改进输出层的设计提升模型的预测准确率。

然而CNN\&Daily Mail数据集的构造方式使得数据集有一定的噪声，此外数据集的问题是自动生成而且答案仅仅是原文中的某个实体名词，对模型的理解能力要求不高。为了解决这些限制问题，Rajpurkar等人\upcite{SQuAD1}发布了大规模数据集SQuAD。SQuAD数据集的问题由众包工人基于文章人工生成，并且问题的答案来源于原文中某一片段，而不像CNN\& Daily Mail数据集仅仅是某个实体单词。由于数据集规模大、质量高，易于评估且具有很好的应用价值等特点获得了广泛的关注度，
极大地推动了MRC领域的发展，很多经典的神经机器阅读理解模型（如Match-LSTM\upcite{MatchLSTM}，DCN\upcite{DCN}，BiDAF\upcite{BiDAF}，R-Net\upcite{RNet}）都是在SQuAD数据集上构建出来的。

为了使得阅读理解任务更加的贴近真实场景，微软亚洲研究院发布了来源于真实应用场景下的数据集MS MARCO\upcite{MSmarco}，问题收集自搜索引擎日志，答案由人工生成。在MS MARCO发布后，机器阅读理解领域涌现出很多的高质量、大规模、不同来源的数据集（如RACE\upcite{RACE}，NarrativeQA\upcite{NarrativeQA}，CoQA\upcite{CoQA}等）。每一个新的阅读理解任务的提出都会伴随着相关数据集的发布，
每一个数据集也都会在原有数据集的基础上增加适当的难度，目的是使得数据集可以真正的考察模型的阅读理解能力。

自2018年随着GPT\upcite{GPT}、BERT\upcite{BERT}等预训练模型的出现，
刷新了众多机器阅读理解任务上模型的最佳性能，
甚至在某些数据集上模型的表现超过人类水平。


%现实生活中人们往往是先提出问题然后阅读文章查找答案，因此SQuAD数据集这种由文章生成问题的构造方式并不符合现实场景下的阅读理解任务，此外限制问题的答案是原文中某一连续的文本不足以回答复杂的问题，对模型的理解能力要求不高。
%在SQuAD发布不久后微软研究院发布了来源于真实场景下的数据集MS MARCO\upcite{MSmarco}，数据集的问题来源于必应搜索日志上用户搜索的问题，从必应搜索的返回结果中选取10篇最相关的段落作为问题的答案依据，答案是人工生成的而不限于原文中某段文本，因此数据集难度更大。类似的数据集还有TriviaQA\upcite{TriviaQA}，DuReader\upcite{DuReader}等。之前的模型如R-Net在这种多段落自由答案形式的数据集上效果并不好，
%Tan等人\upcite{SNet}提出S-Net模型,
%在R-Net的基础上添加段落排名算法,然后利用生成模块生成答案，效果优于R-Net模型。
%
%然而以上大部分的数据集，与问题相关的答案通常集中在单个句子的局部上下文
%这类数据集对模型的推理能力要求不高。因此研究者们尝试难度更大，更加接近于人类阅读理解形式的任务。
%如多步推理阅读理解任务，要求模型从多个段落中逐步检索推理才能找到答案,相关的数据集如
%HotpotQA\upcite{HotpotQA}，WIKIHOP\upcite{WIKIHOP}。
%NarrativeQA\upcite{NarrativeQA}等数据集相继发布，这些数据集中的问题要求模型从多个段落中逐步检索推理才能找到答案

%
%每一个新的数据集都会解决原有数据集存在的一些问题，
%从而不得不设计更加优秀的模型处理这些新的任
%务，MRC领域也因此快速发展。
%目前几乎所有数据集上表现最好的模型都是基于预训练模型的。

本文的目的是对从2015年来机器阅读理解领域的研究任务、相关数据集以及模型做综述。
整体安排如下：第二章概述机器阅读理解任务并且简介各个任务相关的数据集；第三章介绍神经机器阅读理解模型，包括预训练模型出现之前的经典机器阅读理解模型以及基于预训练模型的机器阅读理解模型；\textcolor{red}{第四章我还没想好名字}；第五章讨论机器阅读理解的应用、面临的主要问题以及未来的研究方向；第六章对全文作总结。
%机器阅读理解（Machine Reading Comprehension，MRC）作为一项衡量计算机阅读理解文本能力的任务，是自然语言处理领域（Natural Language Processing，NLP）
%十分重要也是具有挑战性的研究方向。通常情况下，MRC任务就是
%给定一篇或多篇段落文本（passage），要求模型阅读这些段落后回答相关的问题（question）。
%早期的MRC系统主要是基于规则和模式匹配的方法，或者通过概率统计的方式计算问题与文章之间的相似程度。这很难达到深层次的理解文本，
%而且数据集规模比较小，系统难以获得期望的性能也不能实际的应用。
%随着深度学习的兴起以及NLP领域出现的一些经典技术
%如Word2Vec\upcite{word2vec}以及注意力（Attention）机制在NLP领域的应用\upcite{Bahdanau}等，这些技术的发展使得研究人员开始利用神经网络
%构建机器阅读理解模型，
%因此也叫神经机器阅读理解。
%
%Hermann等人\upcite{Hermann}在2015年发布了规模比以往数据集都要大的阅读理解数据集CNN\&Daily Mail，并且提出两个基于神经网络和注意力机制构建的模型（Attentive Reader，Impatient Reader），这项工作可以视为机器阅读理解领域的奠基性工作。此后越来越多的学者在这两个模型的基础上构建效果更好的神经机器阅读理解模型，
%Chen等人\upcite{AR}使用双线性函数以及Kadlec等人\upcite{ASR}采用点积运算的计算方式取代Attentive Reader的加法形式。Sordoni等人\upcite{IAReader}提出IA Reader模型利用循环神经网络的循环计算机制以及Dhingra等人\upcite{GAReader}提出的GA Reader模型通过加深网络的层次达到Impatient Reader模型多步推理的效果。
%
%%而且规模越来越大，形式越来越复杂的数据集也相继发布。
%SQuAD\upcite{SQuAD1}是由斯坦福大学在2016年发布的大规模数据集，问题的答案来源于原文中某一片段而不像CNN\& Daily Mail数据集仅仅是某个实体单词。
%SQuAD数据集的发布极大地推动了MRC领域的发展，很多经典的神经机器阅读理解模型都是在SQuAD数据集上构建出来的。Wang等人\upcite{MatchLSTM}提出Match-LSTM模型，通过计算段落到问题的注意力将问题的语义融合到段落文本中，并且利用指针网络的机制预测答案在原文中的位置。在这之后很多模型受到Match-LSTM的启发，如Wang等人\upcite{RNet}在其基础上添加一层自注意力机制用来加强模型对段落的理解，Xiong等人\upcite{DCN}采用一种动态迭代指针网络的机制来多次迭代预测答案的位置。在2018年
%斯坦福大学又发布了SQuAD 2.0\upcite{SQuAD2}数据集，在SQuAD的基础上增加了五万多个不可回答的问题。
%
%
%在SQuAD发布不久后微软研究院发布了来源于真实场景下的数据集MS MARCO\upcite{MSmarco}，数据集的问题来源于必应搜索日志上用户搜索的问题，从必应搜索的返回结果中选取10篇最相关的段落作为问题的答案依据，答案是人工生成的而不限于某段文本，因此数据集难度更大。类似的数据集还有TriviaQA\upcite{TriviaQA}，DuReader\upcite{DuReader}等。针对这种多段落自由答案形式的任务，Tan等人\upcite{SNet}提出S-Net模型,先
%通过片段抽取模块提取出一段文本作为答案的预测依据,然后利用生成模块生成答案。
%
%然而以上大部分的数据集，与问题相关的答案通常集中在单个句子的局部上下文
%这类数据集对模型的推理能力要求不高。
%为了考察模型的推理能力，HotpotQA\upcite{HotpotQA}，WIKIHOP\upcite{WIKIHOP}，Narrative\upcite{NarrativeQA}等数据集相继发布，这些数据集中的问题要求模型从多个段落中逐步检索推理才能找到答案。此外还有多轮对话形式的阅读理解任务，相关的数据集如CoQA\upcite{CoQA}，QuAC\upcite{QuAC}等。

%每一个新的数据集都会在原有数据集的基础上增加各种各样的难度,从而不得不设计更加优秀的模型处理这些任
%务，MRC领域也因此快速发展。
%自2018年随着ELMo\upcite{ELMo}、GPT\upcite{GPT}、BERT\upcite{BERT}等预训练模型的出现，
%再一次提升了机器阅读理解模型的性能，甚至在某些数据集上模型的表现超过人类水平。
%%目前几乎所有数据集上表现最好的模型都是基于预训练模型的。
%
%本文主要从MRC的具体任务概述出发，总共分5章，结构安排如下：
%第2章介绍机器阅读理解的具体任务以及相应的评估指标；第3章
%介绍神经机器阅读理解模型，包括经典的基于抽取式任务的MRC模型，复杂任务下的MRC模型以及基于预训练模型的MRC模型，对比它们的差异以及优缺点。
%%同时介绍近年来NLP领域最受关注的预训练模型以及如何应用在MRC任务上。
%第4章主要讨论MRC领域的发展历史和目前MRC领域存在的主要问题。
%第5章对MRC领域做总结与展望。