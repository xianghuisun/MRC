\documentclass{article}
%\documentclass{ctexart}
\usepackage{multicol}
\usepackage{wrapfig}
\usepackage{lipsum}
%for long table
\makeatletter
\newenvironment{tablehere}
  {\def\@captype{table}}
 {}

\newenvironment{figurehere}
 {\def\@captype{figure}}
 {}
\makeatother
\usepackage{longtable}
%\documentclass{ctexart}
\usepackage{ctex}%中文
\usepackage{graphicx}
\usepackage{zhlipsum}
\usepackage{color}
\usepackage{multirow}
\usepackage{biblatex}%biber才可以
\addbibresource{ass.bib}
\usepackage{cuted}
\graphicspath{{picture/}}
\usepackage[left=2.5cm,right=1.97cm,top=2.5cm,bottom=2.5cm]{geometry}%设置页边距
\renewcommand{\baselinestretch}{1.25}%行间距
%\usepackage[hidelinks,urlcolor=black,linkcolor=black]{hyperref}%引入超链接包，否则会出现Undefined sequence
\usepackage[hidelinks]{hyperref}
%[colorlinks,urlcolor=black,linkcolor=black]去除超链接中的颜色框
\usepackage{amssymb}%数学符号
\usepackage{amsmath}%数学公式
\usepackage{booktabs}%设置三线表的线粗细
\usepackage{array}%table
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
%\usepackage{cite}
% \ctexset{section={format={\zihao{3} \heiti \bfseries}},
% bibname={\zihao{-4} \heiti \bfseries 参考文献}}

\newcommand{\upcite}[1]{\textsuperscript{\textsuperscript{\cite{#1}}}}
\usepackage{caption}
\DeclareCaptionFont{heiti}{\heiti}
\captionsetup{labelsep=quad,font={small,bf,heiti},skip={4pt}}
\usepackage{geometry}
\title{\heiti \zihao{2} 神经机器阅读理解研究综述}
%\footnotetext{ 投稿日期: 2020-07-19 \\
%\hspace*{1.8em}作者简介: 孙相会（1997-），男，硕士，研究方向为自然语言处理，E-mail: 2357094733@qq.com}
%黑体2号 在标题那页插入脚注


%\author{\zihao{-4} \songti 孙相会 \\ 东北大学 计算机科学与工程学院，沈阳 110169}
\date{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%












\begin{document}
    \maketitle %生成title,author,date

        \input{abstract_part.tex}
%----------------------正文-----------------------
%\begin{multicols}{2}
\input{introduction}

% \end{multicols}
% %在你想要分栏的段落上下加上begin end columns{2}


																																	

\input{dataset.tex}

\section{神经机器阅读理解模型}
%随着大规模机器阅读理解数据集如CNN\&Daily Mail\upcite{CNNDailyMail}，SQuAD\upcite{SQuAD1}等的发布以及
%深度学习技术的发展，神经机器阅读理解模型的性能显著的超过传统的基于规则和特征的模型，随着NLP领域预训练模型的发展，基于预训练模型
%来做MRC任务的模型性能再一次的提升。
Hermann等人\upcite{Hermann}发布的CNN\&Daily Mail数据集以及他们所设计的两个基于神经网络和注意力机制的模型可以看作是MRC领域的奠基性工作，开创了神经机器阅读理解模型。Rajpurkar等人\cite{SQuAD1}在2016年发布的SQuAD数据集是MRC领域里程碑式的数据集，在2016-2018年期间掀起了一阵热潮，很多的神经机器阅读理解模型都是在此期间构建出来的。
填空式数据集本质上可以认为是抽取式数据集的简化形式，而后续的很多任务如对话形式、开放领域形式、多段落形式的阅读理解任务也都是在抽取式任务的形式上设计模型。因此抽取式阅读理解任务是MRC领域的核心，本章主要以抽取式任务的MRC模型为出发点，
安排如下：3.1节分析经典的基于抽取式任务的MRC模型通用架构，3.2节介绍复杂任务下的MRC模型，3.3节介绍目前流行的预训练模型以及如何利用预训练模型设计性能更强大的MRC模型。
\input{based_extrc}

\input{complicated_task.tex}
%由于预训练模型UNILM\upcite{UNILM}改进了BERT的训练任务，
%增加了自回归语言模型以及seq2seq语言模型使得其
%在生成式任务上的效果很好，在CoQA数据集上远远的超过于Reddy等\upcite{CoQA}提出的基准模型。

%下面介绍神经机器阅读理解模型中基于注意力机制的模型和基于预训练的模型。
%\input{embedding_layer.tex}



%\input{interaction_layer.tex}
%
%

\begin{figure}
	\centering
	\includegraphics[width=5cm,height=4cm]{classicTopre}
\end{figure}
\input{pre_train.tex}
%% %\input{model.tex}



%\input{new_trend.tex}
%
\input{discussion.tex}
\section{总结与展望}
本文从机器阅读理解任务的定义出发，第二章概述了机器阅读理解任务以及介绍了不同任务下的数据集和相应的评估标准。
第三章神经机器阅读理解模型进行了分析与研究，主要涉及经典模型
的整体框架，其中详细分析了各个模型在交互层注意力机制的设计。此外还介绍了复杂任务下MRC模型的设计，同时也总结了
目前一些主流的预训练模型，分析了它们之间的差异，列举了一些在预训练模型的基础上改进
的MRC模型。通过各个模型的实验对比结果可以看到基于预训练的模型性能要显著的优于传统的仅仅基于
注意力机制的模型。第四章回顾了MRC领域的发展并且指出了目前MRC领域存在的问题。
%列举了一些目前MRC领域更加复杂的任务并且对每一种任务下相关的模型做了介绍。

机器阅读理解赋予了计算机阅读理解文本的能力，在搜索、对话、医疗以及教育领域都有着广阔的应用空间，未来的研究方向有以下几点值得关注：

1）目前机器阅读理解领域的数据集大多是通用领域方向，而设计专业领域数据集也尤为重要。比如通过利用机器阅读理解技术分析产品说明文档和用户的问题语义从而解决用户对产品的问题达到智能客服服务，或者在医疗诊断中分析大量病例和知识库提供智能医疗服务。


2）目前机器阅读理解主要集中于非结构化的文本领域，而
还有许多其它结构、不同模态的数据如表格、视频、音频、图片等，相关的研究方向如数据库问答，视觉问答等。
多模态阅读理解模型是未来的机器阅读理解发展方向之一。

3）目前很少有机器阅读理解模型融合外部知识，都是直接根据给定的文档回答相关的问题，而人在阅读一篇文章的时候对这篇文章的理解程度和他已经掌握的知识水平有很大关系。因此如果将外部知识源融入模型中那么模型的性能大概率会显著提高。




\printbibliography[title={参考文献}]




\end{document}