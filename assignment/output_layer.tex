\subsection{答案预测层的设计}\label{output}
如前所述，答案预测层的设计要依据答案的形式而设计，下面介绍
各个模型在四类不同的MRC任务上的输出层设计。

1）填空型：这类任务答案的形式是预测问题中缺失的单词，而且缺失的答案来源于文章中。文献\cite{Hermann}
最早提出将问题的语义向量与关注了问题的文章的语义向量拼接成一个向量然后映射到整个词典中预测那个缺失的单词。
这种方法存在的一个问题就是不能够确保预测的单词一定是文章中的词汇，因为它是将最后的输出向量映射到整个词典中，
这就使得模型的预测准确率受到影响。指针网络（Pointer networks\upcite{Ptr}）模型由seq2seq模型演变而来，主要就是
为了解决输出源自于输入的问题，实现方式是利用计算的注意力的权重分布直接输出预测结果，而这种机制正适合
填空型任务以及片段选择型任务。
文献\cite{ASR}提出AS Reader模型正是受到指针网络的启发，对于计算得到的注意力权重分布，将其中相同单词的注意力
权值相加，最后输出具有最大权值的单词最为答案。
填空型任务模型的损失函数可以写
为$L(\theta)=-\displaystyle\frac{1}{N}\sum_{i=1}^{N}\log P_{y_i}$。
其中$\theta$为模型参数，$N$代表样本数目，$y_i$表示文章中第$i$个样本的文章中标准答案的位置。

2）多项选择型：这类任务是从多个候选答案选项中选择正确的选项。处理这种任务最简单的一种方式就是计算模型输出后的
文章的语义信息和选项之间的相似程度，相似程度最高的作为预测的选项，从而将问题变化为句子之间的语义匹配问题。
文献\cite{Co-matching}提出将问题、文章、选项一起方法模型中做交互计算输出一个向量作为输出层的输入，
输出层采用简单的输出维度是1的全连接层，输出的值代表模型对这个选型的打分值，其它的选项类似的处理，值最高的选项作为预测的答案。
最后对所有选项的打分值
做归一化作为模型的损失函数。
多项选择型任务模型的损失函数可以写为
$L(\theta)=-\displaystyle\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{m}\log P_{y_{j}^i}$。
其中$\theta$为模型参数，$N$代表样本数目，$m$代表选项个数，$y_{j}^i$表示第$i$个样本中第$j$个选项是正确答案。

3）片段选择型：这类任务是从文章中提取出来一段连续的单词作为答案，虽然类似于填空型任务输出来源自输入的性质，但是
不像填空型任务仅仅只是预测一个单词。因此填空型
任务答案输出层的设计不能直接用来作为片段选择型任务答案预测层。
由于提取文本的长度不固定，使得这一任务更具有挑战性。
文献\cite{MatchLSTM}受到指针网络的启发提出了两种基于指针网络的输出模型，第一种是序列式模型，利用指针网络以一种序列式的形式生成答案的每一个位置，处理过程类似于seq2seq模型的解码过程，
这种模型下答案的每一个单词可能出现在文本段落的任何一个位置，
这是因为指针网络并没有要求从输入中选择的输出具有连续性。由于答案的长度不固定，因此在段落中设置一个特殊的
位置表示答案的终止点，当预测到这个位置时终止答案的生成。
第二种是边界式模型，不同于序列式模型那样序列的生成答案的每一个位置，由于要预测的答案是一段连续的单词的组合，
因此可以利用指针网络仅仅预测答案的起始位置和终止位置。所预测答案的概率
是预测这两个位置概率的乘积，这种方式相比于
第一种更加的简单而且测试结果表明更加高效。
%\begin{table*}[ht]
%    \centering
%    \caption{模型对比（acc代表准确率）}
%    \vspace{10pt}
%    \begin{tabular}{l c c c}
%        \toprule
%        \multirow{2}{*}{模型}&SQuAD 1.1\upcite{SQuAD1}& SQuAD 2.0\upcite{SQuAD2} & RACE\upcite{RACE}\\
%        \cmidrule(lr){2-2} \cmidrule(lr){3-3} \cmidrule(lr){4-4}
%        &EM/F1&EM/F1& acc \\
%        \midrule
%        Match-LSTM\upcite{MatchLSTM}& 64.7/73.7 & -&-\\
%        \midrule
%        DCN\upcite{Dynamic coattention networks for question answering}& 66.2/75.9 &-&-\\
%        \midrule
%        ReasoNet\upcite{Reasonet}&70.6/79.4 &-&-\\
%        \midrule
%        BiDAF\upcite{Bidirectional attention flow for machine comprehension}&68.0/77.3 &-&-\\
%        \midrule
%        R-Net\upcite{RNet}&72.3/80.7 &-&-\\
%        \midrule
%        QANet(data augmentation x3)\upcite{QANet}& 76.2/84.6&-&-\\
%        \midrule
%        ELMo+BiDAF\upcite{ELMo}&78.6/85.8&-&-\\
%        \midrule
%        GPT-v1\upcite{GPT}&-&-&59.0\\
%        \midrule
%        $\text{BERT}_{large}$(+TriviaQA)\upcite{BERT}& 85.1/91.8 &80.0/83.1&72.0\\
%        \midrule
%        XLNet\upcite{XLNet}&-&86.4/89.1 &81.8\\
%        \midrule
%        DCMN+\upcite{DCMN+}&-&-&82.8\\
%        \midrule
%        RoBERTa\upcite{RoBERTa}&-&86.8/89.8 &83.2\\
%        \midrule
%        ALBERT\upcite{ALBERT}&-&88.1/90.9 &86.5\\
%        \midrule
%        Retro-Reader over ALBERT\upcite{Retrospective}&-&88.1/91.4&-\\
%        \bottomrule
%    \end{tabular}
%\end{table*}

边界式模型的这种设计思想也被后来很多MRC模型采纳。如R-Net\upcite{RNet}采用几乎一样的边界式
模型，只不过解码端的初始状态
采用的是对问题的语义向量加权求和。尽管边界式模型简单有效，但是在文章中可能有些文本片段与标准答案相似，比如初始位置一样，
那么边界式模型有可能陷入局部极值的情况从而提取错误的文本片段。为了处理这个问题，DCN\upcite{DCN}
模型提出一种动态迭代的指针网络作为解码端，利用上一次预测的答案的起始位置和终止位置以及解码端当前的状态来重新评估
下一次预测答案的起始位置和终止位置。多次迭代后选取所有迭代次数中概率最大的情形作为预测答案。
片段选择任务模型的损失函数可以写为
$L(\theta)=-\displaystyle\frac{1}{N}\sum_{i=1}^{N}\log P_{y_i^s}^S+\log P_{y_i^e}^E$。
其中$\theta$为模型参数，$N$代表样本数目，$y_i^s$表示第$i$个样本中标准答案的起始位置在文章中的位置，
$y_i^e$表示第$i$个样本中标准答案的终止位置在文章中的位置。
如果考虑到不可回答的问题，最简单的方式是额外在输出层加上一个输出维度是1的全连接层。
此时的损失函数可以写为
$L(\theta)=-\displaystyle\frac{1}{N}\sum_{i=1}^{N}(\log P_{y_i^s}^S+\log P_{y_i^e}^E)+\log P_{y_i^u}^U$。
其中$y_i^u$表示第$i$个样本中的问题是不可回答的问题。关于带有不可回答问题的阅读理解任务细节见\ref{unknown}节。

4）自由答案型：这类任务的答案形式已经不再是原文中某段文本，而是需要根据文章和问题生成符合语法规范的文本。
这类任务对答案生成模块的能力要求较高。处理生成任务典型的架构是seq2seq模型，文献\cite{PGNet}提出
一种指针生成网络模型（Pointer-Generator Network，PGNet）。这个模型最早提出来用在文本摘要领域，模型结合了seq2seq的
生成机制以及指针网络的拷贝机制，使得模型既能从词典中生成单词又能在原文中拷贝单词，实验结果表明该模型的效果优于传统的seq2seq模型。
% 文献\cite{CoQA}采用三种模型在在CoQA数据集上进行实验。
% 第一种是传统的seq2seq模型，第二种是Pointer-Generator Network\cite{PGNet}，简称PGNet。
% 这个模型最早提出来用在文本摘要领域，模型结合了seq2seq的生成机制以及
% 指针网络的拷贝机制，使得模型既能生成单词又能在原文中拷贝单词，实验结果表明该模型的效果优于传统的seq2seq模型。
% 第三种是DrQA+PGNet模型，其中DrQA\cite{DrQA}是类似于上述
% BiDAF\upcite{Bidirectional attention flow for machine comprehension}，
% RNet\upcite{RNet}等模型的片段抽取模块。整个模型的思想是
% 先利用片段提取模块从文章中提取中与问题最相关的一段文本，然后利用答案生成模块在这个被抽取出来的文本上
% 生成答案。这种（提取模块+生成模块）模型在其它的生成模型中如SNet\upcite{SNet}等广泛使用。
% 实验结果也表明这种模型的效果是最好的。






